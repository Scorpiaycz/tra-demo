{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5KRLS82Y_PX"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /workspace/.pip-modules/lib/python3.8/site-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /workspace/.pip-modules/lib/python3.8/site-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: click in /workspace/.pip-modules/lib/python3.8/site-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /workspace/.pip-modules/lib/python3.8/site-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /workspace/.pip-modules/lib/python3.8/site-packages (from nltk) (2022.6.2)\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --user -U nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKnBD3tLY844",
        "outputId": "5959a8d3-d449-4655-f2f0-0dd81ed20b44"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/gitpod/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/share/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m/workspace/tra-demo/backend/NLP_tools.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000002vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m# input the text\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000002vscode-remote?line=4'>5</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000002vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mAn HTTP request is made by a client, to a named host, which is located on a server. \u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000002vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mThe aim of the request is to access a resource on the server. To make the request, the client uses components of a URL (Uniform Resource Locator), \u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000002vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mwhich includes the information needed to access the resource.\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000002vscode-remote?line=8'>9</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000002vscode-remote?line=9'>10</a>\u001b[0m word_tokenize(text)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=113'>114</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mword_tokenize\u001b[39m(text, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m, preserve_line\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=114'>115</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=115'>116</a>\u001b[0m \u001b[39m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=116'>117</a>\u001b[0m \u001b[39m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=126'>127</a>\u001b[0m \u001b[39m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=127'>128</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=128'>129</a>\u001b[0m     sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=129'>130</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=130'>131</a>\u001b[0m         token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39mtokenize(sent)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=131'>132</a>\u001b[0m     ]\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=95'>96</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msent_tokenize\u001b[39m(text, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=96'>97</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=97'>98</a>\u001b[0m \u001b[39m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=98'>99</a>\u001b[0m \u001b[39m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=103'>104</a>\u001b[0m \u001b[39m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=104'>105</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=105'>106</a>\u001b[0m     tokenizer \u001b[39m=\u001b[39m load(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtokenizers/punkt/\u001b[39;49m\u001b[39m{\u001b[39;49;00mlanguage\u001b[39m}\u001b[39;49;00m\u001b[39m.pickle\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=106'>107</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer\u001b[39m.\u001b[39mtokenize(text)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=746'>747</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<<Loading \u001b[39m\u001b[39m{\u001b[39;00mresource_url\u001b[39m}\u001b[39;00m\u001b[39m>>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=748'>749</a>\u001b[0m \u001b[39m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=749'>750</a>\u001b[0m opened_resource \u001b[39m=\u001b[39m _open(resource_url)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=751'>752</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=752'>753</a>\u001b[0m     resource_val \u001b[39m=\u001b[39m opened_resource\u001b[39m.\u001b[39mread()\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=872'>873</a>\u001b[0m protocol, path_ \u001b[39m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=874'>875</a>\u001b[0m \u001b[39mif\u001b[39;00m protocol \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnltk\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=875'>876</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, path \u001b[39m+\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mopen()\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=876'>877</a>\u001b[0m \u001b[39melif\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=877'>878</a>\u001b[0m     \u001b[39m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=878'>879</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mopen()\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=580'>581</a>\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=581'>582</a>\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=582'>583</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/gitpod/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/share/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "# import module for tokenization\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "# input the text\n",
        "text = \"\"\"\n",
        "An HTTP request is made by a client, to a named host, which is located on a server. \n",
        "The aim of the request is to access a resource on the server. To make the request, the client uses components of a URL (Uniform Resource Locator), \n",
        "which includes the information needed to access the resource.\n",
        "\"\"\"\n",
        "word_tokenize(text)\n",
        "# Challenge: on first try, you may not be run into errors \"resource_not_found\". Attempt to solve this error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_Ivc3KeLa6HN"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/gitpod/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/share/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m/workspace/tra-demo/backend/NLP_tools.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000003vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# Mission: assign the tokens to an array named 'tokens'\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000003vscode-remote?line=1'>2</a>\u001b[0m tokens \u001b[39m=\u001b[39m word_tokenize(text)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=113'>114</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mword_tokenize\u001b[39m(text, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m, preserve_line\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=114'>115</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=115'>116</a>\u001b[0m \u001b[39m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=116'>117</a>\u001b[0m \u001b[39m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=126'>127</a>\u001b[0m \u001b[39m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=127'>128</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=128'>129</a>\u001b[0m     sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=129'>130</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=130'>131</a>\u001b[0m         token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39mtokenize(sent)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=131'>132</a>\u001b[0m     ]\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=95'>96</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msent_tokenize\u001b[39m(text, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=96'>97</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=97'>98</a>\u001b[0m \u001b[39m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=98'>99</a>\u001b[0m \u001b[39m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=103'>104</a>\u001b[0m \u001b[39m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=104'>105</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=105'>106</a>\u001b[0m     tokenizer \u001b[39m=\u001b[39m load(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtokenizers/punkt/\u001b[39;49m\u001b[39m{\u001b[39;49;00mlanguage\u001b[39m}\u001b[39;49;00m\u001b[39m.pickle\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/tokenize/__init__.py?line=106'>107</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer\u001b[39m.\u001b[39mtokenize(text)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=746'>747</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<<Loading \u001b[39m\u001b[39m{\u001b[39;00mresource_url\u001b[39m}\u001b[39;00m\u001b[39m>>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=748'>749</a>\u001b[0m \u001b[39m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=749'>750</a>\u001b[0m opened_resource \u001b[39m=\u001b[39m _open(resource_url)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=751'>752</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=752'>753</a>\u001b[0m     resource_val \u001b[39m=\u001b[39m opened_resource\u001b[39m.\u001b[39mread()\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=872'>873</a>\u001b[0m protocol, path_ \u001b[39m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=874'>875</a>\u001b[0m \u001b[39mif\u001b[39;00m protocol \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnltk\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=875'>876</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, path \u001b[39m+\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mopen()\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=876'>877</a>\u001b[0m \u001b[39melif\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=877'>878</a>\u001b[0m     \u001b[39m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=878'>879</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mopen()\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=580'>581</a>\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[1;32m    <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=581'>582</a>\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='file:///workspace/.pip-modules/lib/python3.8/site-packages/nltk/data.py?line=582'>583</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/gitpod/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/share/nltk_data'\n    - '/home/gitpod/.pyenv/versions/3.8.13/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "# Mission: assign the tokens to an array named 'tokens'\n",
        "tokens = word_tokenize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3NYJs0Bb9-J"
      },
      "source": [
        "Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u3KytuqcIz0",
        "outputId": "980ad3bf-98f9-45ea-df62-9b368327b558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rocks : rock\n"
          ]
        }
      ],
      "source": [
        "#import the module\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# initiate the lemmatizer object\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
        "# Challenge: on first try, you may not be run into errors \"resource_not_found\". Attempt to solve this error.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGmVAaP8cZlz",
        "outputId": "3701af05-ce53-4188-c6cc-e0070337a5b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['An', 'HTTP', 'request', 'is', 'made', 'by', 'a', 'client', ',', 'to', 'a', 'named', 'host', ',', 'which', 'is', 'located', 'on', 'a', 'server', '.', 'The', 'aim', 'of', 'the', 'request', 'is', 'to', 'access', 'a', 'resource', 'on', 'the', 'server', '.', 'To', 'make', 'the', 'request', ',', 'the', 'client', 'us', 'component', 'of', 'a', 'URL', '(', 'Uniform', 'Resource', 'Locator', ')', ',', 'which', 'includes', 'the', 'information', 'needed', 'to', 'access', 'the', 'resource', '.']\n"
          ]
        }
      ],
      "source": [
        "# Mission: Lemmatize all the words in the tokens array\n",
        "new_tokens = []\n",
        "for token in tokens:\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    new_tokens.append(lemmatizer.lemmatize(token))\n",
        "print(new_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xka1cCgKeYfb"
      },
      "source": [
        "Removing stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rS44PQAQcv0Z",
        "outputId": "0d53ddda-97bd-4c86-e8d7-79632796821f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['HTTP', 'request', 'made', 'client', ',', 'named', 'host', ',', 'located', 'server', '.', 'aim', 'request', 'access', 'resource', 'server', '.', 'make', 'request', ',', 'client', 'us', 'component', 'URL', '(', 'Uniform', 'Resource', 'Locator', ')', ',', 'includes', 'information', 'needed', 'access', 'resource', '.']\n"
          ]
        }
      ],
      "source": [
        "# import the module\n",
        "from nltk.corpus import stopwords\n",
        "#assign to globally set stopwords to a local set\n",
        "stop_words = set(stopwords.words('english'))\n",
        "#filter the stopwords from the token\n",
        "filtered_tokens = [token for token in new_tokens if not token.lower() in stop_words]\n",
        "\n",
        "print(filtered_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "POS tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('BuildingBloCS', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('yearly', 'JJ'), ('event', 'NN'), ('that', 'WDT'), ('teaches', 'VBZ'), ('student', 'NN'), ('computing', 'VBG'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "text = \"BuildingBloCS is a yearly event that teaches student computing.\"\n",
        "sentence = nltk.sent_tokenize(text)\n",
        "for sent in sentence:\n",
        "\t print(nltk.pos_tag(nltk.word_tokenize(sent)))\n",
        "# now add your own text to tag it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "USING RAKE ALGORITHM TO EXTRACT KEYWORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rake-nltk in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (1.0.6)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /workspace/.pip-modules/lib/python3.8/site-packages (from rake-nltk) (3.7)\n",
            "Requirement already satisfied: joblib in /workspace/.pip-modules/lib/python3.8/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /workspace/.pip-modules/lib/python3.8/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.64.0)\n",
            "Requirement already satisfied: click in /workspace/.pip-modules/lib/python3.8/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /workspace/.pip-modules/lib/python3.8/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2022.6.2)\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# TO INSTALL RAKE MODULE\n",
        "!pip install rake-nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['uniform resource locator ),',\n",
              " 'client uses components',\n",
              " 'named host',\n",
              " 'information needed',\n",
              " 'http request',\n",
              " 'resource',\n",
              " 'resource',\n",
              " 'client',\n",
              " 'request',\n",
              " 'request',\n",
              " 'url',\n",
              " 'server',\n",
              " 'server',\n",
              " 'make',\n",
              " 'made',\n",
              " 'located',\n",
              " 'includes',\n",
              " 'aim',\n",
              " 'access',\n",
              " 'access']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from rake_nltk import Rake\n",
        "r = Rake()\n",
        "text = \"\"\"\n",
        "An HTTP request is made by a client, to a named host, which is located on a server. \n",
        "The aim of the request is to access a resource on the server. To make the request, the client uses components of a URL (Uniform Resource Locator), \n",
        "which includes the information needed to access the resource.\n",
        "\"\"\"\n",
        "r.extract_keywords_from_text(text)\n",
        "r.get_ranked_phrases()\n",
        "\n",
        "# Mission: One of the results this algorithm outputs is 'uniform resource locator )'. \n",
        "# Clean the text by removing punctuation marks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pytextrank to extract keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "  Downloading spacy-3.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hCollecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /workspace/.pip-modules/lib/python3.8/site-packages (from spacy) (4.64.0)\n",
            "Collecting wasabi<1.1.0,>=0.9.1\n",
            "  Downloading wasabi-0.9.1-py3-none-any.whl (26 kB)\n",
            "Collecting thinc<8.1.0,>=8.0.14\n",
            "  Downloading thinc-8.0.17-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.1/671.1 kB\u001b[0m \u001b[31m147.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy) (2.27.1)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m162.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy) (62.3.2)\n",
            "Collecting srsly<3.0.0,>=2.4.3\n",
            "  Downloading srsly-2.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.7/459.7 kB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.9\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Downloading murmurhash-1.0.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Requirement already satisfied: jinja2 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy) (3.1.2)\n",
            "Collecting numpy>=1.15.0\n",
            "  Downloading numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2\n",
            "  Downloading preshed-3.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.1/130.1 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
            "  Downloading cymem-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
            "Collecting blis<0.8.0,>=0.4.0\n",
            "  Downloading blis-0.7.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m176.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Collecting smart-open<6.0.0,>=5.0.0\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /workspace/.pip-modules/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from jinja2->spacy) (2.1.1)\n",
            "Installing collected packages: wasabi, murmurhash, cymem, typer, spacy-loggers, spacy-legacy, smart-open, pydantic, preshed, numpy, langcodes, catalogue, srsly, pathy, blis, thinc, spacy\n",
            "Successfully installed blis-0.7.7 catalogue-2.0.7 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.7 numpy-1.22.4 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 smart-open-5.2.1 spacy-3.3.0 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.17 typer-0.4.1 wasabi-0.9.1\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pytextrank\n",
            "  Downloading pytextrank-3.2.3-py3-none-any.whl (30 kB)\n",
            "Collecting scipy>=1.7\n",
            "  Downloading scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy>=3.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pytextrank) (3.3.0)\n",
            "Collecting networkx[default]>=2.6\n",
            "  Downloading networkx-2.8.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m165.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphviz>=0.13\n",
            "  Downloading graphviz-0.20-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting icecream>=2.1\n",
            "  Downloading icecream-2.1.2-py2.py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pytextrank) (2.12.0)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from icecream>=2.1->pytextrank) (2.0.5)\n",
            "Requirement already satisfied: executing>=0.3.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from icecream>=2.1->pytextrank) (0.8.3)\n",
            "Collecting pandas>=1.3\n",
            "  Downloading pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m166.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from networkx[default]>=2.6->pytextrank) (1.22.4)\n",
            "Collecting matplotlib>=3.4\n",
            "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m162.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (1.0.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (2.0.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (3.1.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (1.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (0.9.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (21.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (3.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (2.27.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (0.4.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (8.0.17)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /workspace/.pip-modules/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (4.64.0)\n",
            "Requirement already satisfied: setuptools in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (62.3.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (0.7.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (2.4.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (1.8.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (0.6.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from spacy>=3.0->pytextrank) (3.0.6)\n",
            "Requirement already satisfied: six in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from asttokens>=2.0.1->icecream>=2.1->pytextrank) (1.16.0)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (2.8.2)\n",
            "Collecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m191.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.9/930.9 kB\u001b[0m \u001b[31m175.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m176.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.5/503.5 kB\u001b[0m \u001b[31m144.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pathy>=0.3.5->spacy>=3.0->pytextrank) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy>=3.0->pytextrank) (4.2.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (1.26.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /workspace/.pip-modules/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0->pytextrank) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from jinja2->spacy>=3.0->pytextrank) (2.1.1)\n",
            "Installing collected packages: pytz, scipy, pillow, networkx, kiwisolver, graphviz, fonttools, cycler, colorama, pandas, matplotlib, icecream, pytextrank\n",
            "Successfully installed colorama-0.4.4 cycler-0.11.0 fonttools-4.33.3 graphviz-0.20 icecream-2.1.2 kiwisolver-1.4.2 matplotlib-3.5.2 networkx-2.8.2 pandas-1.4.2 pillow-9.1.1 pytextrank-3.2.3 pytz-2022.1 scipy-1.8.1\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install spacy\n",
        "!pip3 install pytextrank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32m/workspace/tra-demo/backend/NLP_tools.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000016vscode-remote?line=3'>4</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000016vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mAn HTTP request is made by a client, to a named host, which is located on a server. \u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000016vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mThe aim of the request is to access a resource on the server. To make the request, the client uses components of a URL (Uniform Resource Locator), \u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000016vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mwhich includes the information needed to access the resource.\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000016vscode-remote?line=7'>8</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000016vscode-remote?line=8'>9</a>\u001b[0m \u001b[39m# load a spaCy model, depending on language, scale, etc.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000016vscode-remote?line=9'>10</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39men_core_web_sm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000016vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m# add PyTextRank to the spaCy pipeline\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://scorpiaycz-trademo-pmhmzbkua3d.ws-us46.gitpod.io/workspace/tra-demo/backend/NLP_tools.ipynb#ch0000016vscode-remote?line=11'>12</a>\u001b[0m nlp\u001b[39m.\u001b[39madd_pipe(\u001b[39m\"\u001b[39m\u001b[39mtextrank\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=30'>31</a>\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=31'>32</a>\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=35'>36</a>\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=36'>37</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=37'>38</a>\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=38'>39</a>\u001b[0m \n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=39'>40</a>\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=48'>49</a>\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=49'>50</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=50'>51</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=51'>52</a>\u001b[0m         name, vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig\n\u001b[1;32m     <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/__init__.py?line=52'>53</a>\u001b[0m     )\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/util.py:427\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/util.py?line=424'>425</a>\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/util.py?line=425'>426</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/spacy/util.py?line=426'>427</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import pytextrank\n",
        "# example text\n",
        "text = \"\"\"\n",
        "An HTTP request is made by a client, to a named host, which is located on a server. \n",
        "The aim of the request is to access a resource on the server. To make the request, the client uses components of a URL (Uniform Resource Locator), \n",
        "which includes the information needed to access the resource.\n",
        "\"\"\"\n",
        "# load a spaCy model, depending on language, scale, etc.\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# add PyTextRank to the spaCy pipeline\n",
        "nlp.add_pipe(\"textrank\")\n",
        "doc = nlp(text)\n",
        "# examine the top-ranked phrases in the document\n",
        "for phrase in doc._.phrases[:10]:\n",
        "    print(phrase.text)\n",
        "\n",
        "# there are multiple results with 'a' as part of the keyphrase,\n",
        "# can we possible remove them for they keywords to be better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementation for the TRA. \n",
        "Using a technique you have learnt just now OR using a new method you have found\n",
        "Design a function that takes in a bunch of sentences, and return a list with \n",
        "1. the sentence with the keywords replaced with blanks '_'\n",
        "2. the keywords\n",
        "eg. The mitochondria is the powerhouse of the cell\n",
        "returns\n",
        "['The _______ is the _______ of the cell', ['mitochondria','powerhouse']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "NLP tools",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('3.8.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
